{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extensions to Linear Models - Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this lab, you'll practice many concepts learned in this section, from adding interactions and polynomials to your model to AIC and BIC!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "You will be able to:\n",
    "- Build a linear regression model with polynomial features/interactions\n",
    "- Perform regularization\n",
    "- Use AIC and BIC to select the best value for the regularization parameter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at a Baseline Boston Housing Data Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the Boston housing data set, use all the predictors in their scaled version (using `preprocessing.scale`. Look at a baseline model using *scaled variables* as predictors. Use 5-fold cross-validation this time and use the $R^2$ score to evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7176778617934925"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "boston = load_boston()\n",
    "X = pd.DataFrame(boston.data, columns = boston.feature_names)\n",
    "y = pd.DataFrame(boston.target, columns = ['Price'])\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "y = scaler.fit_transform(y)\n",
    "X = pd.DataFrame(X, columns = boston.feature_names)\n",
    "y = pd.DataFrame(y, columns = ['MEDV'])\n",
    "linreg = LinearRegression()\n",
    "crossvalidation = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "r2 = np.mean(cross_val_score(linreg, X, y, scoring=\"r2\", cv=crossvalidation))\n",
    "r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Include interactions\n",
    "\n",
    "Look at all the possible combinations of variables for interactions by adding interactions one by one to the baseline model. Next, evaluate that model using 5-fold classification and store the $R^2$ to compare it with the baseline model.\n",
    "\n",
    "You've created code for this before in the interactions lab, yet this time, you have scaled the variables so the outcomes may look different. \n",
    "\n",
    "Print the 7 most important interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Interaction</th>\n",
       "      <th>R2</th>\n",
       "      <th>var1</th>\n",
       "      <th>var2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>RM_LSTAT</td>\n",
       "      <td>0.783201</td>\n",
       "      <td>RM</td>\n",
       "      <td>LSTAT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>RM_TAX</td>\n",
       "      <td>0.775268</td>\n",
       "      <td>RM</td>\n",
       "      <td>TAX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>RM_RAD</td>\n",
       "      <td>0.770118</td>\n",
       "      <td>RM</td>\n",
       "      <td>RAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>RM_PTRATIO</td>\n",
       "      <td>0.763594</td>\n",
       "      <td>RM</td>\n",
       "      <td>PTRATIO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>INDUS_RM</td>\n",
       "      <td>0.756628</td>\n",
       "      <td>INDUS</td>\n",
       "      <td>RM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>NOX_RM</td>\n",
       "      <td>0.746111</td>\n",
       "      <td>NOX</td>\n",
       "      <td>RM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>RM_AGE</td>\n",
       "      <td>0.742141</td>\n",
       "      <td>RM</td>\n",
       "      <td>AGE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Interaction        R2   var1     var2\n",
       "56    RM_LSTAT  0.783201     RM    LSTAT\n",
       "53      RM_TAX  0.775268     RM      TAX\n",
       "52      RM_RAD  0.770118     RM      RAD\n",
       "54  RM_PTRATIO  0.763594     RM  PTRATIO\n",
       "25    INDUS_RM  0.756628  INDUS       RM\n",
       "42      NOX_RM  0.746111    NOX       RM\n",
       "50      RM_AGE  0.742141     RM      AGE"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "from itertools import combinations\n",
    "combs = combinations(X.columns,2)\n",
    "fits = {'Interaction':[],'R2':[], 'var1':[],'var2':[]}\n",
    "for comb in combs:\n",
    "    Xc = X.copy()\n",
    "    column_name = comb[0]+'_'+comb[1]\n",
    "    Xc[column_name] = Xc[comb[0]]*Xc[comb[1]]\n",
    "    r2 = np.mean(cross_val_score(linreg, Xc, y, scoring=\"r2\", cv=crossvalidation))\n",
    "    fits['Interaction'].append(column_name)\n",
    "    fits['R2'].append(r2)\n",
    "    fits['var1'].append(comb[0])\n",
    "    fits['var2'].append(comb[1])\n",
    "fits_df = pd.DataFrame(fits)\n",
    "top_7 = fits_df.sort_values(by = 'R2', ascending = False).head(7)\n",
    "top_7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write code to include the 7 most important interactions in your data set by adding 7 columns. Name the columns \"var1_var2\" with var1 and var2 the two variables in the interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>RM_LSTAT</th>\n",
       "      <th>RM_TAX</th>\n",
       "      <th>RM_RAD</th>\n",
       "      <th>RM_PTRATIO</th>\n",
       "      <th>INDUS_RM</th>\n",
       "      <th>NOX_RM</th>\n",
       "      <th>RM_AGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.067815</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.314815</td>\n",
       "      <td>0.577505</td>\n",
       "      <td>0.641607</td>\n",
       "      <td>0.269203</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.208015</td>\n",
       "      <td>0.287234</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.089680</td>\n",
       "      <td>0.051791</td>\n",
       "      <td>0.120130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.165879</td>\n",
       "      <td>0.039164</td>\n",
       "      <td>0.181807</td>\n",
       "      <td>0.370531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000236</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.242302</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.172840</td>\n",
       "      <td>0.547998</td>\n",
       "      <td>0.782698</td>\n",
       "      <td>0.348962</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.104962</td>\n",
       "      <td>0.553191</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.204470</td>\n",
       "      <td>0.112049</td>\n",
       "      <td>0.057519</td>\n",
       "      <td>0.023826</td>\n",
       "      <td>0.303148</td>\n",
       "      <td>0.132781</td>\n",
       "      <td>0.094716</td>\n",
       "      <td>0.428917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000236</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.242302</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.172840</td>\n",
       "      <td>0.694386</td>\n",
       "      <td>0.599382</td>\n",
       "      <td>0.348962</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.104962</td>\n",
       "      <td>0.553191</td>\n",
       "      <td>0.989737</td>\n",
       "      <td>0.063466</td>\n",
       "      <td>0.044070</td>\n",
       "      <td>0.072884</td>\n",
       "      <td>0.030191</td>\n",
       "      <td>0.384128</td>\n",
       "      <td>0.168251</td>\n",
       "      <td>0.120017</td>\n",
       "      <td>0.416202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000293</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.063050</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.150206</td>\n",
       "      <td>0.658555</td>\n",
       "      <td>0.441813</td>\n",
       "      <td>0.448545</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.066794</td>\n",
       "      <td>0.648936</td>\n",
       "      <td>0.994276</td>\n",
       "      <td>0.033389</td>\n",
       "      <td>0.021988</td>\n",
       "      <td>0.043987</td>\n",
       "      <td>0.057266</td>\n",
       "      <td>0.427360</td>\n",
       "      <td>0.041522</td>\n",
       "      <td>0.098919</td>\n",
       "      <td>0.290958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000705</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.063050</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.150206</td>\n",
       "      <td>0.687105</td>\n",
       "      <td>0.528321</td>\n",
       "      <td>0.448545</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.066794</td>\n",
       "      <td>0.648936</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.099338</td>\n",
       "      <td>0.068255</td>\n",
       "      <td>0.045894</td>\n",
       "      <td>0.059748</td>\n",
       "      <td>0.445887</td>\n",
       "      <td>0.043322</td>\n",
       "      <td>0.103207</td>\n",
       "      <td>0.363012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CRIM    ZN     INDUS  CHAS       NOX        RM       AGE       DIS  \\\n",
       "0  0.000000  0.18  0.067815   0.0  0.314815  0.577505  0.641607  0.269203   \n",
       "1  0.000236  0.00  0.242302   0.0  0.172840  0.547998  0.782698  0.348962   \n",
       "2  0.000236  0.00  0.242302   0.0  0.172840  0.694386  0.599382  0.348962   \n",
       "3  0.000293  0.00  0.063050   0.0  0.150206  0.658555  0.441813  0.448545   \n",
       "4  0.000705  0.00  0.063050   0.0  0.150206  0.687105  0.528321  0.448545   \n",
       "\n",
       "        RAD       TAX   PTRATIO         B     LSTAT  RM_LSTAT    RM_TAX  \\\n",
       "0  0.000000  0.208015  0.287234  1.000000  0.089680  0.051791  0.120130   \n",
       "1  0.043478  0.104962  0.553191  1.000000  0.204470  0.112049  0.057519   \n",
       "2  0.043478  0.104962  0.553191  0.989737  0.063466  0.044070  0.072884   \n",
       "3  0.086957  0.066794  0.648936  0.994276  0.033389  0.021988  0.043987   \n",
       "4  0.086957  0.066794  0.648936  1.000000  0.099338  0.068255  0.045894   \n",
       "\n",
       "     RM_RAD  RM_PTRATIO  INDUS_RM    NOX_RM    RM_AGE  \n",
       "0  0.000000    0.165879  0.039164  0.181807  0.370531  \n",
       "1  0.023826    0.303148  0.132781  0.094716  0.428917  \n",
       "2  0.030191    0.384128  0.168251  0.120017  0.416202  \n",
       "3  0.057266    0.427360  0.041522  0.098919  0.290958  \n",
       "4  0.059748    0.445887  0.043322  0.103207  0.363012  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "for row in top_7.values:\n",
    "    X[row[0]] = X[row[2]]*X[row[3]]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Include Polynomials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try polynomials of 2, 3 and 4 for each variable, in a similar way you did for interactions (by looking at your baseline model and seeing how $R^2$ increases). Do understand that when going for a polynomial of 4, the particular column is raised to the power of 2 and 3 as well in other terms. We only want to include \"pure\" polynomials, so make sure no interactions are included. We want the result to return a list that contain tuples of the form:\n",
    "\n",
    "`(var_name, degree, R2)`, so eg. `('DIS', 3, 0.732)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "fits = {'Variable':[],'degree':[], 'R2':[]}\n",
    "for column,degree in product(X.columns[0:-7],[2,3,4]): # Only 'pure' columns... whatever that means\n",
    "    Xc = X.copy()\n",
    "    poly = PolynomialFeatures(degree,include_bias = False)\n",
    "    data = poly.fit_transform(Xc[[column]])\n",
    "    temp_df = pd.concat([Xc.drop(column, axis = 1), pd.DataFrame(data)], axis = 1)\n",
    "    r2 = np.mean(cross_val_score(linreg, temp_df, y, scoring=\"r2\", cv=crossvalidation))\n",
    "    fits['Variable'].append(column)\n",
    "    fits['R2'].append(r2)\n",
    "    fits['degree'].append(degree)\n",
    "fits_df = pd.DataFrame(fits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each variable, print out the maximum R2 possible when including Polynomials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>degree</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>DIS</td>\n",
       "      <td>3</td>\n",
       "      <td>0.803287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>LSTAT</td>\n",
       "      <td>4</td>\n",
       "      <td>0.795389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CRIM</td>\n",
       "      <td>2</td>\n",
       "      <td>0.793518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NOX</td>\n",
       "      <td>4</td>\n",
       "      <td>0.793377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>TAX</td>\n",
       "      <td>4</td>\n",
       "      <td>0.792650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>AGE</td>\n",
       "      <td>2</td>\n",
       "      <td>0.792060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ZN</td>\n",
       "      <td>4</td>\n",
       "      <td>0.791477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>RM</td>\n",
       "      <td>4</td>\n",
       "      <td>0.791200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>B</td>\n",
       "      <td>2</td>\n",
       "      <td>0.790300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>RAD</td>\n",
       "      <td>4</td>\n",
       "      <td>0.790035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CHAS</td>\n",
       "      <td>2</td>\n",
       "      <td>0.789785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>INDUS</td>\n",
       "      <td>3</td>\n",
       "      <td>0.789703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>PTRATIO</td>\n",
       "      <td>2</td>\n",
       "      <td>0.789217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Variable  degree        R2\n",
       "22      DIS       3  0.803287\n",
       "38    LSTAT       4  0.795389\n",
       "0      CRIM       2  0.793518\n",
       "14      NOX       4  0.793377\n",
       "29      TAX       4  0.792650\n",
       "18      AGE       2  0.792060\n",
       "5        ZN       4  0.791477\n",
       "17       RM       4  0.791200\n",
       "33        B       2  0.790300\n",
       "26      RAD       4  0.790035\n",
       "9      CHAS       2  0.789785\n",
       "7     INDUS       3  0.789703\n",
       "30  PTRATIO       2  0.789217"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "fits_df.loc[fits_df.groupby('Variable')['R2'].idxmax()].sort_values('R2',ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which two variables seem to benefit most from adding Polynomial terms?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add Polynomials for the two features that seem to benefit the most, as in have the best R squared compared to the baseline model. For each of the two feature, raise to the Polynomial that generates the best result. Make sure to start from the data set `df_inter` so the final data set has both interactions and polynomials in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIS first\n",
    "poly = PolynomialFeatures(3)\n",
    "data = poly.fit_transform(X[['DIS']])\n",
    "X = X.merge(pd.DataFrame(data, columns = ['DIS0', 'DIS1', 'DIS2', 'DIS3']), left_index = True, right_index = True).drop(['DIS','DIS0'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now LSTAT\n",
    "poly = PolynomialFeatures(4)\n",
    "data = poly.fit_transform(X[['LSTAT']])\n",
    "X = X.merge(pd.DataFrame(data, columns = ['LSTAT0', 'LSTAT1', 'LSTAT2', 'LSTAT3','LSTAT4']), left_index = True, right_index = True).drop(['LSTAT','LSTAT0'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check out your final data set and make sure that your interaction terms as well as your polynomial terms are included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>...</th>\n",
       "      <th>INDUS_RM</th>\n",
       "      <th>NOX_RM</th>\n",
       "      <th>RM_AGE</th>\n",
       "      <th>DIS1</th>\n",
       "      <th>DIS2</th>\n",
       "      <th>DIS3</th>\n",
       "      <th>LSTAT1</th>\n",
       "      <th>LSTAT2</th>\n",
       "      <th>LSTAT3</th>\n",
       "      <th>LSTAT4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.067815</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.314815</td>\n",
       "      <td>0.577505</td>\n",
       "      <td>0.641607</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.208015</td>\n",
       "      <td>0.287234</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039164</td>\n",
       "      <td>0.181807</td>\n",
       "      <td>0.370531</td>\n",
       "      <td>0.269203</td>\n",
       "      <td>0.072470</td>\n",
       "      <td>0.019509</td>\n",
       "      <td>0.089680</td>\n",
       "      <td>0.008042</td>\n",
       "      <td>0.000721</td>\n",
       "      <td>0.000065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000236</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.242302</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.172840</td>\n",
       "      <td>0.547998</td>\n",
       "      <td>0.782698</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.104962</td>\n",
       "      <td>0.553191</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132781</td>\n",
       "      <td>0.094716</td>\n",
       "      <td>0.428917</td>\n",
       "      <td>0.348962</td>\n",
       "      <td>0.121774</td>\n",
       "      <td>0.042495</td>\n",
       "      <td>0.204470</td>\n",
       "      <td>0.041808</td>\n",
       "      <td>0.008549</td>\n",
       "      <td>0.001748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000236</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.242302</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.172840</td>\n",
       "      <td>0.694386</td>\n",
       "      <td>0.599382</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.104962</td>\n",
       "      <td>0.553191</td>\n",
       "      <td>...</td>\n",
       "      <td>0.168251</td>\n",
       "      <td>0.120017</td>\n",
       "      <td>0.416202</td>\n",
       "      <td>0.348962</td>\n",
       "      <td>0.121774</td>\n",
       "      <td>0.042495</td>\n",
       "      <td>0.063466</td>\n",
       "      <td>0.004028</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>0.000016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000293</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.063050</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.150206</td>\n",
       "      <td>0.658555</td>\n",
       "      <td>0.441813</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.066794</td>\n",
       "      <td>0.648936</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041522</td>\n",
       "      <td>0.098919</td>\n",
       "      <td>0.290958</td>\n",
       "      <td>0.448545</td>\n",
       "      <td>0.201192</td>\n",
       "      <td>0.090244</td>\n",
       "      <td>0.033389</td>\n",
       "      <td>0.001115</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000705</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.063050</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.150206</td>\n",
       "      <td>0.687105</td>\n",
       "      <td>0.528321</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.066794</td>\n",
       "      <td>0.648936</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043322</td>\n",
       "      <td>0.103207</td>\n",
       "      <td>0.363012</td>\n",
       "      <td>0.448545</td>\n",
       "      <td>0.201192</td>\n",
       "      <td>0.090244</td>\n",
       "      <td>0.099338</td>\n",
       "      <td>0.009868</td>\n",
       "      <td>0.000980</td>\n",
       "      <td>0.000097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CRIM    ZN     INDUS  CHAS       NOX        RM       AGE       RAD  \\\n",
       "0  0.000000  0.18  0.067815   0.0  0.314815  0.577505  0.641607  0.000000   \n",
       "1  0.000236  0.00  0.242302   0.0  0.172840  0.547998  0.782698  0.043478   \n",
       "2  0.000236  0.00  0.242302   0.0  0.172840  0.694386  0.599382  0.043478   \n",
       "3  0.000293  0.00  0.063050   0.0  0.150206  0.658555  0.441813  0.086957   \n",
       "4  0.000705  0.00  0.063050   0.0  0.150206  0.687105  0.528321  0.086957   \n",
       "\n",
       "        TAX   PTRATIO    ...     INDUS_RM    NOX_RM    RM_AGE      DIS1  \\\n",
       "0  0.208015  0.287234    ...     0.039164  0.181807  0.370531  0.269203   \n",
       "1  0.104962  0.553191    ...     0.132781  0.094716  0.428917  0.348962   \n",
       "2  0.104962  0.553191    ...     0.168251  0.120017  0.416202  0.348962   \n",
       "3  0.066794  0.648936    ...     0.041522  0.098919  0.290958  0.448545   \n",
       "4  0.066794  0.648936    ...     0.043322  0.103207  0.363012  0.448545   \n",
       "\n",
       "       DIS2      DIS3    LSTAT1    LSTAT2    LSTAT3    LSTAT4  \n",
       "0  0.072470  0.019509  0.089680  0.008042  0.000721  0.000065  \n",
       "1  0.121774  0.042495  0.204470  0.041808  0.008549  0.001748  \n",
       "2  0.121774  0.042495  0.063466  0.004028  0.000256  0.000016  \n",
       "3  0.201192  0.090244  0.033389  0.001115  0.000037  0.000001  \n",
       "4  0.201192  0.090244  0.099338  0.009868  0.000980  0.000097  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full model R-squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out the R-squared of the full model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8042354225748314"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "linreg = LinearRegression()\n",
    "crossvalidation = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "r2 = np.mean(cross_val_score(linreg, X, y, scoring=\"r2\", cv=crossvalidation))\n",
    "r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the best Lasso regularization parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You've learned that, when using Lasso regularization, your coefficients shrink to 0 when using a higher regularization parameter. Now the question is which value we should choose for the regularization parameter. \n",
    "\n",
    "This is where the AIC and BIC come in handy! We'll use both criteria in what follows and perform cross-validation to select an optimal value of the regularization parameter alpha of the Lasso estimator.\n",
    "\n",
    "Read the page here: https://scikit-learn.org/stable/auto_examples/linear_model/plot_lasso_model_selection.html and create a similar plot as the first one listed on the page. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Information-criterion for model selection')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Your code here\n",
    "from sklearn.linear_model import LassoCV, LassoLarsCV, LassoLarsIC\n",
    "\n",
    "model_bic = LassoLarsIC(criterion='bic')\n",
    "model_bic.fit(X, y)\n",
    "alpha_bic_ = model_bic.alpha_\n",
    "\n",
    "model_aic = LassoLarsIC(criterion='aic')\n",
    "model_aic.fit(X, y)\n",
    "alpha_aic_ = model_aic.alpha_\n",
    "\n",
    "def plot_ic_criterion(model, name, color):\n",
    "    alpha_ = model.alpha_\n",
    "    alphas_ = model.alphas_\n",
    "    criterion_ = model.criterion_\n",
    "    plt.plot(-np.log10(alphas_), criterion_, '--', color=color,\n",
    "             linewidth=3, label='%s criterion' % name)\n",
    "    plt.axvline(-np.log10(alpha_), color=color, linewidth=3,\n",
    "                label='{0:1.2f}: {1} estimate'.format(-np.log10(alpha_), name))\n",
    "    plt.xlabel('-log(alpha)')\n",
    "    plt.ylabel('criterion')\n",
    "    \n",
    "plt.figure()\n",
    "plot_ic_criterion(model_aic, 'AIC', 'b')\n",
    "plot_ic_criterion(model_bic, 'BIC', 'r')\n",
    "plt.legend()\n",
    "plt.title('Information-criterion for model selection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_aic = 10**(-4.13)\n",
    "alpha_bic = 10**(-3.03)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze the final result\n",
    "\n",
    "Finally, use the best value for regularization parameter according to AIC and BIC and compare the R squared parameters and MSE using train-test-split. Compare with the baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring(X_train, X_test, y_train, y_test, model):\n",
    "    X = [X_train, X_test]\n",
    "    y = [y_train, y_test]\n",
    "    r2 = []\n",
    "    mse = []\n",
    "    for Xi, yi in zip(X,y):\n",
    "        model.fit(Xi,yi)\n",
    "        y_hat = model.predict(Xi)\n",
    "        crossvalidation = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "        r2.append(np.mean(cross_val_score(model, Xi, yi, scoring=\"r2\", cv=crossvalidation)))\n",
    "        mse.append(mean_squared_error(yi, y_hat))\n",
    "    print('R-squared Train: {0:1.3f}'.format(r2[0]))\n",
    "    print('R-squared Test: {0:1.3f}'.format(r2[1]))\n",
    "    print('MSE Train: {0:1.3E}'.format(mse[0]))\n",
    "    print('MSE Test: {0:1.3E}'.format(mse[1]))\n",
    "    \n",
    "    return (r2, mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared Train: 0.795\n",
      "R-squared Test: 0.490\n",
      "MSE Train: 6.350E-03\n",
      "MSE Test: 5.126E-03\n"
     ]
    }
   ],
   "source": [
    "# Code for baseline model\n",
    "linreg = LinearRegression()\n",
    "_ = scoring(X_train, X_test, y_train, y_test, linreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared Train: 0.801\n",
      "R-squared Test: 0.631\n",
      "MSE Train: 6.725E-03\n",
      "MSE Test: 6.156E-03\n"
     ]
    }
   ],
   "source": [
    "# code for lasso with alpha from AIC\n",
    "from sklearn.linear_model import Lasso\n",
    "reg = Lasso(alpha = alpha_aic)\n",
    "_ = scoring(X_train, X_test, y_train, y_test, reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared Train: 0.754\n",
      "R-squared Test: 0.715\n",
      "MSE Train: 8.757E-03\n",
      "MSE Test: 7.972E-03\n"
     ]
    }
   ],
   "source": [
    "# code for lasso with alpha from BIC\n",
    "reg = Lasso(alpha = alpha_bic)\n",
    "_ = scoring(X_train, X_test, y_train, y_test, reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level Up - Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Lasso Path\n",
    "\n",
    "From this section, you know that when using lasso, more parameters shrink to zero as your regularization parameter goes up. In Scikit-Learn there is a function lasso_path which visualizes the shrinkage of the coefficients while alpha changes. Try this out yourself!\n",
    "\n",
    "https://scikit-learn.org/stable/auto_examples/linear_model/plot_lasso_coordinate_descent_path.html#sphx-glr-auto-examples-linear-model-plot-lasso-coordinate-descent-path-py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AIC and BIC for subset selection\n",
    "This notebook shows how you can use AIC and BIC purely for feature selection. Try this code out on our Boston Housing data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://xavierbourretsicotte.github.io/subset_selection.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You now know how to create better linear models and how to use AIC and BIC for both feature selection and to optimize your regularization parameter when performing Ridge and Lasso. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
